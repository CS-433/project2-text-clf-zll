{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataset\n",
    "with open('train_pos_full.txt') as f:\n",
    "    documents1 = []\n",
    "    for line in f:\n",
    "        new_line = '__label__1 ' + line\n",
    "        documents1.append(new_line)\n",
    "\n",
    "with open('train_neg_full.txt') as f:\n",
    "    documents2 = []\n",
    "    for line in f:\n",
    "        new_line = '__label__-1 ' + line\n",
    "        documents2.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documents1 + documents2\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "train = open(\"train_full.txt\", \"w\", encoding='utf-8')\n",
    "for element in documents:\n",
    "    train.write(element)\n",
    "train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust parameters\n",
    "# Can also adjust bucket, dim, and loss\n",
    "model = fasttext.train_supervised(input = 'train_full.txt', lr=0.1, epoch=2, wordNgrams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "test = []\n",
    "with open(\"test_data.txt\") as f:\n",
    "    for line in f:\n",
    "        line = ','.join(line.split(',')[1:])\n",
    "        test.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "pred = []\n",
    "for i in test:\n",
    "    pred.append(model.predict(i[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain classification labels from the prediction results\n",
    "lab_pred = []\n",
    "for i in pred:\n",
    "    if str(i[0]) == \"('__label__1',)\":\n",
    "        lab_pred.append(1)\n",
    "    else:\n",
    "        lab_pred.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv submission file\n",
    "idx = [i for i in range(1,len(lab_pred)+1)]\n",
    "dict_ = {\n",
    "    \"Id\" : idx,\n",
    "    \"Prediction\" : lab_pred\n",
    "}\n",
    "pred_df = pd.DataFrame(dict_)\n",
    "pred_df.to_csv(\"pred1.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain accuracy of 0.853 and F1 score 0.856 on AIcrowd using this tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = open(\"test_mod.txt\", \"w\")\n",
    "for element in test:\n",
    "    test1.write(element)\n",
    "test1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using fastText's automatic hyperparameter optimization\n",
    "model_auto = fasttext.train_supervised(input = 'train_full.txt', autotuneValidationFile='test_mod.txt', autotuneDuration=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_auto = []\n",
    "for i in test:\n",
    "    pred_auto.append(model_auto.predict(i[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pred_auto = []\n",
    "for i in pred_auto:\n",
    "    if str(i[0]) == \"('__label__1',)\":\n",
    "        lab_pred_auto.append(1)\n",
    "    else:\n",
    "        lab_pred_auto.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [i for i in range(1,len(lab_pred_auto)+1)]\n",
    "dict_ = {\n",
    "    \"Id\" : idx,\n",
    "    \"Prediction\" : lab_pred_auto\n",
    "}\n",
    "pred_df = pd.DataFrame(dict_)\n",
    "pred_df.to_csv(\"pred2.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automatic model gives us accuracy 0.816 and F1 score 0.817 on AIcrowd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
